{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动生成金庸文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "射雕英雄传\r\n",
      "\r\n",
      "金庸\r\n",
      "\r\n",
      "第一回风雪惊变\r\n",
      "\r\n",
      "钱塘江浩浩江水，日日夜夜无穷无尽的从临安牛家村边绕过，东流入海\r\n",
      "江畔一排数十株乌柏树，叶子似火烧般红，正是八月天时\r\n",
      "村前村后的野草刚起始变黄，一抹斜阳映照之下，更增了几分萧索\r\n",
      "两株大松树下围着一堆村民，男男女女和十几个小，正自聚精会神的听着一个瘦削的老者说话\r\n",
      "\r\n",
      "那说话人五十来岁年纪，一件青布长袍早洗得褪成了蓝灰色\r\n",
      "只听他两片梨花木板碰了几下，右手中竹棒在一面小羯鼓上敲起得得连声\r\n",
      "唱道：小桃无主自开花，烟草茫茫带晚鸦\r\n",
      "\r\n",
      "几处败垣围故井，向来一一是人家\r\n",
      "\r\n",
      "那说话人将木板敲了几下，说道：这首七言诗，说的是兵火过后，原来是家家户户，都变成了断墙残瓦的破败之地\r\n",
      "小人刚才说到那叶老汉一家四口，悲欢离合，聚了又散，散了又聚\r\n",
      "他四人给金兵冲散，好容易又再团聚，欢天喜地的回到故乡，却见房屋已给金兵烧得干干净净，无可奈何，只得去到汴梁，想觅个生计\r\n",
      "不料想：天有不测风云，人有旦夕祸福\r\n",
      "他四人刚进汴梁城，迎面便过来一队金兵\r\n",
      "带兵的头儿一双三角眼觑将过去，只见那叶三姐生得美貌，跳下马来，当即一把抱住，哈哈大笑，便将她放上了马鞍，说道：‘小姑娘，跟我回家，服侍老爷\r\n",
      "’那叶三姐如何肯从\r\n",
      "拼命挣扎\r\n",
      "那金兵长官喝道：‘你不肯从我，便杀了你的父母兄弟／提起狼牙棒，一棒打在叶四郎的头上，登时脑浆迸裂，一命呜呼\r\n",
      "正是：阴间新添枉死鬼，阳间不见少年人１叶老汉和妈妈吓得呆了，扑将上去，搂住了儿子的死尸，放声大哭\r\n",
      "那长官提起狼牙棒，一棒一个，又都了账\r\n",
      "那叶三姐却不啼哭，说道：‘长官休得凶恶，我跟你回家便了．那长官大喜，将叶三姐带得回家\r\n",
      "不料叶三姐觑他不防，突然抢步过去，拔出那长官的腰刀，对准了他心口，一刀刺将过去，说时迟，那时快，这一刀刺去，眼见便可报得父母兄弟的大仇\r\n",
      "不料那长官久经战阵，武艺精熟，顺手一推，叶三姐登时摔了出去，那长官刚骂得一声：‘小贱人／叶三姐已举起钢刀，在脖子中一勒\r\n",
      "可怜她：花容月貌无双女，惆怅芳魂赴九泉\r\n",
      "\r\n",
      "他说一段，唱一段，只听得众村民无不咬牙切齿，愤怒叹息\r\n",
      "\r\n",
      "那人又说道：众位看官，常言道得好：为人切莫用欺心，举头三尺有神明\r\n",
      "\r\n",
      "若还作恶无报应，天下凶徒人吃人\r\n",
      "\r\n",
      "可是那金兵占了我大宋天下，杀人放火，奸淫掳掠，无恶不作，却又不见他遭到什么报应\r\n",
      "只怪我大宋官家不争气，\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import codecs\n",
    "\n",
    "with zipfile.ZipFile(\"./sd.zip\", \"r\") as f:\n",
    "    f.extractall(\"./\")     \n",
    "    \n",
    "with codecs.open('sd.txt', encoding='utf-8') as f:\n",
    "    print f.read()[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size = 4442\n"
     ]
    }
   ],
   "source": [
    "def read_content(path):\n",
    "    with codecs.open(path, encoding='utf-8') as ins:\n",
    "        return ins.read()\n",
    "    \n",
    "# Return a dict which maps each char into an unique int id\n",
    "def build_vocab(path):\n",
    "    content = list(read_content(path))\n",
    "    idx = 1 # 0 is left for zero-padding\n",
    "    the_vocab = {}\n",
    "    for word in content:\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        if not word in the_vocab:\n",
    "            the_vocab[word] = idx\n",
    "            idx += 1\n",
    "    return the_vocab\n",
    "\n",
    "# Encode a sentence with int ids\n",
    "def text2id(sentence, the_vocab):\n",
    "    words = list(sentence)\n",
    "    return [the_vocab[w] for w in words if len(w) > 0]\n",
    "            \n",
    "# build char vocabluary from input\n",
    "vocab = build_vocab(\"./sd.txt\")\n",
    "print('vocab size = %d' %(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lstm\n",
    "# Each line contains at most 129 chars. \n",
    "seq_len = 151\n",
    "# embedding dimension, which maps a character to a 256-dimension vector\n",
    "num_embed = 256\n",
    "# number of lstm layers\n",
    "num_lstm_layer = 3\n",
    "# hidden unit in LSTM cell\n",
    "num_hidden = 512\n",
    "\n",
    "symbol = lstm.lstm_unroll(\n",
    "    num_lstm_layer, \n",
    "    seq_len,\n",
    "    len(vocab) + 1,\n",
    "    num_hidden=num_hidden,\n",
    "    num_embed=num_embed,\n",
    "    num_label=len(vocab) + 1, \n",
    "    dropout=0.2)\n",
    "\n",
    "\"\"\"test_seq_len\"\"\"\n",
    "data_file = codecs.open(\"./sd.txt\", encoding='utf-8')\n",
    "for line in data_file:\n",
    "    assert len(line) <= seq_len + 1, \"seq_len is smaller than maximum line length. Current line length is %d. Line content is: %s\" % (len(line), line)\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of dataset ==================\n",
      "bucket of len 151 : 30463 samples\n"
     ]
    }
   ],
   "source": [
    "import bucket_io\n",
    "\n",
    "# The batch size for training\n",
    "batch_size = 32\n",
    "\n",
    "# initalize states for LSTM\n",
    "init_c = [('l%d_init_c'%l, (batch_size, num_hidden)) for l in range(num_lstm_layer)]\n",
    "init_h = [('l%d_init_h'%l, (batch_size, num_hidden)) for l in range(num_lstm_layer)]\n",
    "init_states = init_c + init_h\n",
    "\n",
    "# Even though BucketSentenceIter supports various length examples,\n",
    "# we simply use the fixed length version here\n",
    "data_train = bucket_io.BucketSentenceIter(\n",
    "    \"./sd.txt\", \n",
    "    vocab, \n",
    "    [seq_len], \n",
    "    batch_size,             \n",
    "    init_states, \n",
    "    seperate_char='\\n',\n",
    "    text2id=text2id, \n",
    "    read_content=read_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:26: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n",
      "INFO:root:Start training with [gpu(0)]\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# We will show a quick demo with only 1 epoch. In practice, we can set it to be 100\n",
    "num_epoch = 1\n",
    "# learning rate \n",
    "learning_rate = 0.01\n",
    "\n",
    "# Evaluation metric\n",
    "def Perplexity(label, pred):\n",
    "    loss = 0.\n",
    "    for i in range(pred.shape[0]):\n",
    "        loss += -np.log(max(1e-10, pred[i][int(label[i])]))\n",
    "    return np.exp(loss / label.size)\n",
    "\n",
    "model = mx.model.FeedForward(\n",
    "    ctx=mx.gpu(0),\n",
    "    symbol=symbol,\n",
    "    num_epoch=num_epoch,\n",
    "    learning_rate=learning_rate,\n",
    "    momentum=0,\n",
    "    wd=0.0001,\n",
    "    initializer=mx.init.Xavier(factor_type=\"in\", magnitude=2.34))\n",
    "\n",
    "model.fit(X=data_train,\n",
    "          eval_metric=mx.metric.np(Perplexity),\n",
    "          batch_end_callback=mx.callback.Speedometer(batch_size, 20),\n",
    "          epoch_end_callback=mx.callback.do_checkpoint(\"sdtxt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rnn_model import LSTMInferenceModel\n",
    "\n",
    "\n",
    "# helper strcuture for prediction\n",
    "def MakeRevertVocab(vocab):\n",
    "    dic = {}\n",
    "    for k, v in vocab.items():\n",
    "        dic[v] = k\n",
    "    return dic\n",
    "\n",
    "# make input from char\n",
    "def MakeInput(char, vocab, arr):\n",
    "    idx = vocab[char]\n",
    "    tmp = np.zeros((1,))\n",
    "    tmp[0] = idx\n",
    "    arr[:] = tmp\n",
    "\n",
    "# helper function for random sample \n",
    "def _cdf(weights):\n",
    "    total = sum(weights)\n",
    "    result = []\n",
    "    cumsum = 0\n",
    "    for w in weights:\n",
    "        cumsum += w\n",
    "        result.append(cumsum / total)\n",
    "    return result\n",
    "\n",
    "def _choice(population, weights):\n",
    "    assert len(population) == len(weights)\n",
    "    cdf_vals = _cdf(weights)\n",
    "    x = random.random()\n",
    "    idx = bisect.bisect(cdf_vals, x)\n",
    "    return population[idx]\n",
    "\n",
    "# we can use random output or fixed output by choosing largest probability\n",
    "def MakeOutput(prob, vocab, sample=False, temperature=1.):\n",
    "    if sample == False:\n",
    "        idx = np.argmax(prob, axis=1)[0]\n",
    "    else:\n",
    "        fix_dict = [\"\"] + [vocab[i] for i in range(1, len(vocab) + 1)]\n",
    "        scale_prob = np.clip(prob, 1e-6, 1 - 1e-6)\n",
    "        rescale = np.exp(np.log(scale_prob) / temperature)\n",
    "        rescale[:] /= rescale.sum()\n",
    "        return _choice(fix_dict, rescale[0, :])\n",
    "    try:\n",
    "        char = vocab[idx]\n",
    "    except:\n",
    "        char = ''\n",
    "    return char"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
