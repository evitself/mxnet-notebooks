{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Handwritten Digit Recognition\n",
    "\n",
    "This tutorial guides you through a classic computer vision application: identify hand written digits with neural networks. \n",
    "\n",
    "## Load data\n",
    "\n",
    "We first fetch the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, which is a commonly used dataset for handwritten digit recognition. Each image in this dataset has been resized into 28x28 with grayscale value between 0 and 254. The following codes download and load the images and the according labels into `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import struct\n",
    "def download_data(url, force_download=True): \n",
    "    fname = url.split(\"/\")[-1]\n",
    "    if force_download or not os.path.exists(fname):\n",
    "        urllib.urlretrieve(url, fname)\n",
    "    return fname\n",
    "\n",
    "def read_data(label_url, image_url):\n",
    "    with gzip.open(download_data(label_url)) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(download_data(image_url), 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return (label, image)\n",
    "\n",
    "path='http://yann.lecun.com/exdb/mnist/'\n",
    "(train_lbl, train_img) = read_data(\n",
    "    path+'train-labels-idx1-ubyte.gz', path+'train-images-idx3-ubyte.gz')\n",
    "(val_lbl, val_img) = read_data(\n",
    "    path+'t10k-labels-idx1-ubyte.gz', path+'t10k-images-idx3-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the first 10 images and print their labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAA/CAYAAADwizNIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyNAJgiBcBDJ0giAIF4EMnSAIwkX4P9JCW/Bhbv/nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x49ae2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(train_img[i], cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label: %s' % (train_lbl[0:10],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create data iterators for MXNet. The data iterator, which is similar the iterator, returns a batch of data in each `next()` call. A batch contains several images with its according labels. These images are stored in a 4-D matrix with shape `(batch_size, num_channels, width, height)`. For the MNIST dataset, there is only one color channel, and both width and height are 28. In addition, we often shuffle the images used for training, which accelerates the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def to4d(img):\n",
    "    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n",
    "\n",
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(to4d(train_img), train_lbl, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(to4d(val_img), val_lbl, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron\n",
    "\n",
    "A multilayer perceptron contains several fully-connected layers. A fully-connected layer, with an *n x m* input matrix *X* outputs a matrix *Y* with size *n x k*, where *k* is often called as the hidden size. This layer has two parameters, the *m x k* weight matrix *W* and the *m x 1* bias vector *b*. It compute the outputs with\n",
    "\n",
    "$$Y = W X + b.$$\n",
    "\n",
    "The output of a fully-connected layer is often feed into an activation layer, which performs element-wise operations. Two common options are the sigmoid function, or the rectifier (or \"relu\") function, which outputs the max of 0 and the input.\n",
    "\n",
    "The last fully-connected layer often has the hidden size equals to the number of classes in the dataset. Then we stack a softmax layer, which map the input into a probability score. Again assume the input *X* has size *n x m*:\n",
    "\n",
    "$$ \\left[\\frac{\\exp(x_{i1})}{\\sum_{j=1}^m \\exp(x_{ij})},\\ldots, \\frac{\\exp(x_{im})}{\\sum_{j=1}^m \\exp(x_{ij})}\\right] $$\n",
    "\n",
    "Defining the multilayer perceptron in MXNet is straightforward, which has shown as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\graphviz\\files.pyc\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\graphviz\\files.pyc\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\graphviz\\backend.pyc\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data)\u001b[0m\n\u001b[1;32m    126\u001b[0m             raise RuntimeError('failed to execute %r, '\n\u001b[1;32m    127\u001b[0m                 \u001b[1;34m'make sure the Graphviz executables '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 'are on your systems\\' path' % args)\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' path"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x49a17f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a place holder variable for the input data\n",
    "data = mx.sym.Variable('data')\n",
    "# Flatten the data from 4-D shape (batch_size, num_channel, width, height) \n",
    "# into 2-D (batch_size, num_channel*width*height)\n",
    "data = mx.sym.Flatten(data=data)\n",
    "\n",
    "# The first fully-connected layer\n",
    "fc1  = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=128)\n",
    "# Apply relu to the output of the first fully-connnected layer\n",
    "act1 = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the according activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, name='fc2', num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, name='relu2', act_type=\"relu\")\n",
    "\n",
    "# The thrid fully-connected layer, note that the hidden size should be 10, which is the number of unique digits\n",
    "fc3  = mx.sym.FullyConnected(data=act2, name='fc3', num_hidden=10)\n",
    "# The softmax and loss layer\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')\n",
    "\n",
    "# We visualize the network structure with output size (the batch_size is ignored.)\n",
    "shape = {\"data\" : (batch_size, 1, 28, 28)}\n",
    "mx.viz.plot_network(symbol=mlp, shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both the network definition and data iterators are ready. We can start training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n",
      "INFO:root:Start training with [gpu(0)]\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 72992.72 samples/sec\tTrain-accuracy=0.111100\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 74906.38 samples/sec\tTrain-accuracy=0.111250\n",
      "INFO:root:Epoch[0] Batch [600]\tSpeed: 86956.51 samples/sec\tTrain-accuracy=0.242900\n",
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Time cost=3.814\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.469000\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 84745.83 samples/sec\tTrain-accuracy=0.662800\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 84033.64 samples/sec\tTrain-accuracy=0.791350\n",
      "INFO:root:Epoch[1] Batch [600]\tSpeed: 83681.98 samples/sec\tTrain-accuracy=0.838600\n",
      "INFO:root:Epoch[1] Resetting Data Iterator\n",
      "INFO:root:Epoch[1] Time cost=0.719\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.867800\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 83333.33 samples/sec\tTrain-accuracy=0.872000\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 85106.42 samples/sec\tTrain-accuracy=0.900450\n",
      "INFO:root:Epoch[2] Batch [600]\tSpeed: 84745.74 samples/sec\tTrain-accuracy=0.911000\n",
      "INFO:root:Epoch[2] Resetting Data Iterator\n",
      "INFO:root:Epoch[2] Time cost=0.717\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.918900\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 88105.73 samples/sec\tTrain-accuracy=0.920000\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 86580.11 samples/sec\tTrain-accuracy=0.930450\n",
      "INFO:root:Epoch[3] Batch [600]\tSpeed: 88888.83 samples/sec\tTrain-accuracy=0.937200\n",
      "INFO:root:Epoch[3] Resetting Data Iterator\n",
      "INFO:root:Epoch[3] Time cost=0.690\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.938500\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 84033.56 samples/sec\tTrain-accuracy=0.941800\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 82304.52 samples/sec\tTrain-accuracy=0.947000\n",
      "INFO:root:Epoch[4] Batch [600]\tSpeed: 83333.33 samples/sec\tTrain-accuracy=0.950400\n",
      "INFO:root:Epoch[4] Resetting Data Iterator\n",
      "INFO:root:Epoch[4] Time cost=0.726\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.951600\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 86580.11 samples/sec\tTrain-accuracy=0.952950\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 84388.19 samples/sec\tTrain-accuracy=0.956500\n",
      "INFO:root:Epoch[5] Batch [600]\tSpeed: 86580.11 samples/sec\tTrain-accuracy=0.958900\n",
      "INFO:root:Epoch[5] Resetting Data Iterator\n",
      "INFO:root:Epoch[5] Time cost=0.704\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.958100\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 86956.51 samples/sec\tTrain-accuracy=0.961750\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 83333.33 samples/sec\tTrain-accuracy=0.964050\n",
      "INFO:root:Epoch[6] Batch [600]\tSpeed: 78124.99 samples/sec\tTrain-accuracy=0.964800\n",
      "INFO:root:Epoch[6] Resetting Data Iterator\n",
      "INFO:root:Epoch[6] Time cost=0.733\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.963600\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 76923.08 samples/sec\tTrain-accuracy=0.968450\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 87336.30 samples/sec\tTrain-accuracy=0.969400\n",
      "INFO:root:Epoch[7] Batch [600]\tSpeed: 87336.30 samples/sec\tTrain-accuracy=0.969650\n",
      "INFO:root:Epoch[7] Resetting Data Iterator\n",
      "INFO:root:Epoch[7] Time cost=0.723\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.967800\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 88105.73 samples/sec\tTrain-accuracy=0.973050\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 86956.51 samples/sec\tTrain-accuracy=0.973300\n",
      "INFO:root:Epoch[8] Batch [600]\tSpeed: 86206.94 samples/sec\tTrain-accuracy=0.973800\n",
      "INFO:root:Epoch[8] Resetting Data Iterator\n",
      "INFO:root:Epoch[8] Time cost=0.695\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.969000\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 81632.61 samples/sec\tTrain-accuracy=0.976850\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 80321.26 samples/sec\tTrain-accuracy=0.976350\n",
      "INFO:root:Epoch[9] Batch [600]\tSpeed: 83333.33 samples/sec\tTrain-accuracy=0.977150\n",
      "INFO:root:Epoch[9] Resetting Data Iterator\n",
      "INFO:root:Epoch[9] Time cost=0.741\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.971000\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "model = mx.model.FeedForward(\n",
    "    ctx = mx.gpu(0),\n",
    "    symbol = mlp,       # network structure\n",
    "    num_epoch = 10,     # number of data passes for training \n",
    "    learning_rate = 0.1 # learning rate of SGD \n",
    ")\n",
    "model.fit(\n",
    "    X=train_iter,       # training data\n",
    "    eval_data=val_iter, # validation data\n",
    "    batch_end_callback = mx.callback.Speedometer(batch_size, 200) # output progress for each 200 data batches\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After training is done, we can predict a single image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAFfCAYAAADptc+BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhxMvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c8012cf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as 7 with probability 0.999391\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "plt.imshow(val_img[0], cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "prob = model.predict(val_img[0:1].astype(np.float32)/255)[0]\n",
    "assert max(prob) > 0.99, \"Low prediction accuracy.\"\n",
    "print 'Classified as %d with probability %f' % (prob.argmax(), max(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the accuracy given a data iterator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 96.820000%\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "valid_acc = model.score(val_iter)\n",
    "print 'Validation accuracy: %f%%' % (valid_acc *100,)\n",
    "assert valid_acc > 0.95, \"Low validation accuracy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more, we can recognizes the digit written on the below box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style type=\"text/css\">\n",
       "  canvas { border: 1px solid black; }\n",
       "</style>\n",
       "\n",
       "<div id=\"board\">\n",
       "\n",
       "  <canvas id=\"myCanvas\" width=\"100px\" height=\"100px\">\n",
       "    Sorry, your browser doesn't support canvas technology.\n",
       "  </canvas>\n",
       "\n",
       "  <p>\n",
       "\n",
       "    <button id=\"classify\" onclick=\"classify()\">\n",
       "      Classify\n",
       "    </button>\n",
       "\n",
       "    <button id=\"clear\" onclick=\"myClear()\">\n",
       "      Clear\n",
       "    </button>\n",
       "    Result: \n",
       "    <input type=\"text\" id=\"result_output\" size=\"5\" value=\"\">\n",
       "\n",
       "  </p>\n",
       "\n",
       "</div>\n",
       "\n",
       "<script type = \"text/JavaScript\" src = \"https://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js?ver=1.4.2\" > </script>\n",
       "\n",
       "<script type = \"text/javascript\" >\n",
       "\n",
       "    function init() {\n",
       "        var myCanvas = document.getElementById(\"myCanvas\");\n",
       "        var curColor = $('#selectColor option:selected').val();\n",
       "        if (myCanvas) {\n",
       "            var isDown = false;\n",
       "            var ctx = myCanvas.getContext(\"2d\");\n",
       "            var canvasX, canvasY;\n",
       "            ctx.lineWidth = 8;\n",
       "            $(myCanvas).mousedown(function(e) {\n",
       "                isDown = true;\n",
       "                ctx.beginPath();\n",
       "                var parentOffset = $(this).parent().offset();\n",
       "                canvasX = e.pageX - parentOffset.left;\n",
       "                canvasY = e.pageY - parentOffset.top;\n",
       "                ctx.moveTo(canvasX, canvasY);\n",
       "            }).mousemove(function(e) {\n",
       "                if (isDown != false) {\n",
       "                    var parentOffset = $(this).parent().offset();\n",
       "                    canvasX = e.pageX - parentOffset.left;\n",
       "                    canvasY = e.pageY - parentOffset.top;\n",
       "                    ctx.lineTo(canvasX, canvasY);\n",
       "                    ctx.strokeStyle = curColor;\n",
       "                    ctx.stroke();\n",
       "                }\n",
       "            }).mouseup(function(e) {\n",
       "                isDown = false;\n",
       "                ctx.closePath();\n",
       "            });\n",
       "        }\n",
       "        $('#selectColor').change(function() {\n",
       "            curColor = $('#selectColor option:selected').val();\n",
       "        });\n",
       "    }\n",
       "init();\n",
       "\n",
       "function handle_output(out) {\n",
       "    document.getElementById(\"result_output\").value = out.content.data[\"text/plain\"];\n",
       "}\n",
       "\n",
       "function classify() {\n",
       "    var kernel = IPython.notebook.kernel;\n",
       "    var myCanvas = document.getElementById(\"myCanvas\");\n",
       "    data = myCanvas.toDataURL('image/png');\n",
       "    document.getElementById(\"result_output\").value = \"\";\n",
       "    kernel.execute(\"classify('\" + data + \"')\", {\n",
       "        'iopub': {\n",
       "            'output': handle_output\n",
       "        }\n",
       "    }, {\n",
       "        silent: false\n",
       "    });\n",
       "}\n",
       "\n",
       "function myClear() {\n",
       "    var myCanvas = document.getElementById(\"myCanvas\");\n",
       "    myCanvas.getContext(\"2d\").clearRect(0, 0, myCanvas.width, myCanvas.height);\n",
       "}\n",
       "\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def classify(img):\n",
    "    img = img[len('data:image/png;base64,'):].decode('base64')\n",
    "    img = cv2.imdecode(np.fromstring(img, np.uint8), -1)\n",
    "    img = cv2.resize(img[:,:,3], (28,28))\n",
    "    img = img.astype(np.float32).reshape((1,1,28,28))/255.0\n",
    "    return model.predict(img)[0].argmax()\n",
    "\n",
    "'''\n",
    "To see the model in action, run the demo notebook at\n",
    "https://github.com/dmlc/mxnet-notebooks/blob/master/python/tutorials/mnist.ipynb.\n",
    "'''\n",
    "HTML(filename=\"mnist_demo.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "Note that the previous fully-connected layer simply reshapes the image into a vector during training. It ignores the spatial information that pixels are correlated on both horizontal and vertical dimensions. The convolutional layer aims to improve this drawback by using a more structural weight $W$. Instead of simply matrix-matrix multiplication, it uses 2-D convolution to obtain the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://thatindiandude.github.io/images/conv.png\" style=\"height: 75%; width: 75%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have multiple feature maps, each with their own weight matrices, to capture different features: \n",
    "<img src=\"https://thatindiandude.github.io/images/filters.png\" style=\"height: 75%; width: 75%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the convolutional layer, another major change of the convolutional neural network is the adding of pooling layers. A pooling layer reduce a $n\\times m$ (often called kernal size) image patch into a single value to make the network less sensitive to the spatial location.\n",
    "\n",
    "<img src=\"https://thatindiandude.github.io/images/pooling.png\" style=\"height: 75%; width: 75%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\graphviz\\files.pyc\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\graphviz\\files.pyc\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\graphviz\\backend.pyc\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data)\u001b[0m\n\u001b[1;32m    126\u001b[0m             raise RuntimeError('failed to execute %r, '\n\u001b[1;32m    127\u001b[0m                 \u001b[1;34m'make sure the Graphviz executables '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 'are on your systems\\' path' % args)\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' path"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2afb8d68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mx.symbol.Variable('data')\n",
    "# first conv layer\n",
    "conv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# second conv layer\n",
    "conv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# first fullc layer\n",
    "flatten = mx.sym.Flatten(data=pool2)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "# second fullc\n",
    "fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n",
    "# softmax loss\n",
    "lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')\n",
    "mx.viz.plot_network(symbol=lenet, shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that LeNet is more complex than the previous multilayer perceptron, so we use GPU instead of CPU for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\u001b[91m[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n",
      "INFO:root:Start training with [gpu(0)]\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 21246.94 samples/sec\tTrain-accuracy=0.111550\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 23678.45 samples/sec\tTrain-accuracy=0.113800\n",
      "INFO:root:Epoch[0] Batch [600]\tSpeed: 23676.68 samples/sec\tTrain-accuracy=0.110600\n",
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Time cost=2.639\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.113500\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 23831.23 samples/sec\tTrain-accuracy=0.149400\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 23667.46 samples/sec\tTrain-accuracy=0.780650\n",
      "INFO:root:Epoch[1] Batch [600]\tSpeed: 23671.74 samples/sec\tTrain-accuracy=0.912300\n",
      "INFO:root:Epoch[1] Resetting Data Iterator\n",
      "INFO:root:Epoch[1] Time cost=2.535\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.935700\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 23709.24 samples/sec\tTrain-accuracy=0.942450\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 23602.33 samples/sec\tTrain-accuracy=0.957550\n",
      "INFO:root:Epoch[2] Batch [600]\tSpeed: 23586.94 samples/sec\tTrain-accuracy=0.964650\n",
      "INFO:root:Epoch[2] Resetting Data Iterator\n",
      "INFO:root:Epoch[2] Time cost=2.545\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.970200\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 23784.07 samples/sec\tTrain-accuracy=0.971200\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 23692.30 samples/sec\tTrain-accuracy=0.975100\n",
      "INFO:root:Epoch[3] Batch [600]\tSpeed: 23679.82 samples/sec\tTrain-accuracy=0.976250\n",
      "INFO:root:Epoch[3] Resetting Data Iterator\n",
      "INFO:root:Epoch[3] Time cost=2.535\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.979500\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 23785.40 samples/sec\tTrain-accuracy=0.979900\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 23686.64 samples/sec\tTrain-accuracy=0.981900\n",
      "INFO:root:Epoch[4] Batch [600]\tSpeed: 23704.04 samples/sec\tTrain-accuracy=0.980700\n",
      "INFO:root:Epoch[4] Resetting Data Iterator\n",
      "INFO:root:Epoch[4] Time cost=2.535\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.982500\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 23740.93 samples/sec\tTrain-accuracy=0.984100\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 23670.94 samples/sec\tTrain-accuracy=0.986350\n",
      "INFO:root:Epoch[5] Batch [600]\tSpeed: 23675.28 samples/sec\tTrain-accuracy=0.984400\n",
      "INFO:root:Epoch[5] Resetting Data Iterator\n",
      "INFO:root:Epoch[5] Time cost=2.538\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.984600\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 23825.26 samples/sec\tTrain-accuracy=0.986750\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 23705.14 samples/sec\tTrain-accuracy=0.988550\n",
      "INFO:root:Epoch[6] Batch [600]\tSpeed: 23710.37 samples/sec\tTrain-accuracy=0.986350\n",
      "INFO:root:Epoch[6] Resetting Data Iterator\n",
      "INFO:root:Epoch[6] Time cost=2.532\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.986400\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 23811.82 samples/sec\tTrain-accuracy=0.988800\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 23713.21 samples/sec\tTrain-accuracy=0.990200\n",
      "INFO:root:Epoch[7] Batch [600]\tSpeed: 23710.62 samples/sec\tTrain-accuracy=0.988350\n",
      "INFO:root:Epoch[7] Resetting Data Iterator\n",
      "INFO:root:Epoch[7] Time cost=2.532\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.987700\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 23741.21 samples/sec\tTrain-accuracy=0.990350\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 23655.82 samples/sec\tTrain-accuracy=0.991600\n",
      "INFO:root:Epoch[8] Batch [600]\tSpeed: 23653.22 samples/sec\tTrain-accuracy=0.989900\n",
      "INFO:root:Epoch[8] Resetting Data Iterator\n",
      "INFO:root:Epoch[8] Time cost=2.539\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.987600\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 23753.31 samples/sec\tTrain-accuracy=0.991800\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 23663.07 samples/sec\tTrain-accuracy=0.992850\n",
      "INFO:root:Epoch[9] Batch [600]\tSpeed: 23688.74 samples/sec\tTrain-accuracy=0.990850\n",
      "INFO:root:Epoch[9] Resetting Data Iterator\n",
      "INFO:root:Epoch[9] Time cost=2.537\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.988300\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "model = mx.model.FeedForward(\n",
    "    ctx = mx.gpu(0),     # use GPU 0 for training, others are same as before\n",
    "    symbol = lenet,       \n",
    "    num_epoch = 10,     \n",
    "    learning_rate = 0.1)\n",
    "model.fit(\n",
    "    X=train_iter,  \n",
    "    eval_data=val_iter, \n",
    "    batch_end_callback = mx.callback.Speedometer(batch_size, 200)\n",
    ") \n",
    "assert model.score(val_iter) > 0.98, \"Low validation accuracy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, with the same hyper-parameters, LeNet achieves 98.7% validation accuracy, which improves on the previous multilayer perceptron accuracy of 96.6%.\n",
    "\n",
    "Because we rewrite the model parameters in `mod`, now we can try the previous digit recognition box again to check if or not the new CNN model improves the classification accuracy."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
