{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-100 State-of-Art Model\n",
    "----\n",
    "\n",
    "In this example, we will show a new state-of-art result on CIFAR-100.\n",
    "We use a sub-Inception Network with Randomized ReLU (RReLU), and achieved 75.68% accuracy on CIFAR-100.\n",
    "\n",
    "We trained from raw pixel directly, only random crop from 3x28x28 from original 3x32x32 image with random flip, which is same to other experiments. \n",
    "\n",
    "We don't do any parameter search, all hyper-parameters come from ImageNet experience, and this work is just for fun. Definitely you can improve it.\n",
    "\n",
    "Train this network requires 3796MB GPU Memory.\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "| Model                       | Test Accuracy |\n",
    "| --------------------------- | ------------- |\n",
    "| **Sub-Inception + RReLU** [1], [2]   | **75.68%**       |\n",
    "| Highway Network  [3] | 67.76%        |\n",
    "| Deeply Supervised Network [4]   | 65.43%        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step we will set up basic Factories for Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvFactory(data, num_filter, kernel, stride=(1,1), pad=(0, 0), name=None, suffix=''):\n",
    "    conv = mx.symbol.Convolution(data=data, num_filter=num_filter, kernel=kernel, stride=stride, pad=pad, name='conv_%s%s' %(name, suffix))\n",
    "    bn = mx.symbol.BatchNorm(data=conv, name='bn_%s%s' %(name, suffix))\n",
    "    act = mx.symbol.LeakyReLU(data=bn, act_type='rrelu', name='rrelu_%s%s' %(name, suffix))\n",
    "    return act\n",
    "\n",
    "def InceptionFactoryA(data, num_1x1, num_3x3red, num_3x3, num_d3x3red, num_d3x3, pool, proj, name):\n",
    "    # 1x1\n",
    "    c1x1 = ConvFactory(data=data, num_filter=num_1x1, kernel=(1, 1), name=('%s_1x1' % name))\n",
    "    # 3x3 reduce + 3x3\n",
    "    c3x3r = ConvFactory(data=data, num_filter=num_3x3red, kernel=(1, 1), name=('%s_3x3' % name), suffix='_reduce')\n",
    "    c3x3 = ConvFactory(data=c3x3r, num_filter=num_3x3, kernel=(3, 3), pad=(1, 1), name=('%s_3x3' % name))\n",
    "    # double 3x3 reduce + double 3x3\n",
    "    cd3x3r = ConvFactory(data=data, num_filter=num_d3x3red, kernel=(1, 1), name=('%s_double_3x3' % name), suffix='_reduce')\n",
    "    cd3x3 = ConvFactory(data=cd3x3r, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), name=('%s_double_3x3_0' % name))\n",
    "    cd3x3 = ConvFactory(data=cd3x3, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), name=('%s_double_3x3_1' % name))\n",
    "    # pool + proj\n",
    "    pooling = mx.symbol.Pooling(data=data, kernel=(3, 3), stride=(1, 1), pad=(1, 1), pool_type=pool, name=('%s_pool_%s_pool' % (pool, name)))\n",
    "    cproj = ConvFactory(data=pooling, num_filter=proj, kernel=(1, 1), name=('%s_proj' %  name))\n",
    "    # concat\n",
    "    concat = mx.symbol.Concat(*[c1x1, c3x3, cd3x3, cproj], name='ch_concat_%s_chconcat' % name)\n",
    "    return concat\n",
    "\n",
    "def InceptionFactoryB(data, num_3x3red, num_3x3, num_d3x3red, num_d3x3, name):\n",
    "    # 3x3 reduce + 3x3\n",
    "    c3x3r = ConvFactory(data=data, num_filter=num_3x3red, kernel=(1, 1), name=('%s_3x3' % name), suffix='_reduce')\n",
    "    c3x3 = ConvFactory(data=c3x3r, num_filter=num_3x3, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=('%s_3x3' % name))\n",
    "    # double 3x3 reduce + double 3x3\n",
    "    cd3x3r = ConvFactory(data=data, num_filter=num_d3x3red, kernel=(1, 1),  name=('%s_double_3x3' % name), suffix='_reduce')\n",
    "    cd3x3 = ConvFactory(data=cd3x3r, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=('%s_double_3x3_0' % name))\n",
    "    cd3x3 = ConvFactory(data=cd3x3, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=('%s_double_3x3_1' % name))\n",
    "    # pool + proj\n",
    "    pooling = mx.symbol.Pooling(data=data, kernel=(3, 3), stride=(2, 2), pool_type=\"max\", name=('max_pool_%s_pool' % name))\n",
    "    # concat\n",
    "    concat = mx.symbol.Concat(*[c3x3, cd3x3, pooling], name='ch_concat_%s_chconcat' % name)\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Network by using Factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception(nhidden, grad_scale):\n",
    "    # data\n",
    "    data = mx.symbol.Variable(name=\"data\")\n",
    "    # stage 2\n",
    "    in3a = InceptionFactoryA(data, 64, 64, 64, 64, 96, \"avg\", 32, '3a')\n",
    "    in3b = InceptionFactoryA(in3a, 64, 64, 96, 64, 96, \"avg\", 64, '3b')\n",
    "    in3c = InceptionFactoryB(in3b, 128, 160, 64, 96, '3c')\n",
    "    # stage 3\n",
    "    in4a = InceptionFactoryA(in3c, 224, 64, 96, 96, 128, \"avg\", 128, '4a')\n",
    "    in4b = InceptionFactoryA(in4a, 192, 96, 128, 96, 128, \"avg\", 128, '4b')\n",
    "    in4c = InceptionFactoryA(in4b, 160, 128, 160, 128, 160, \"avg\", 128, '4c')\n",
    "    in4d = InceptionFactoryA(in4c, 96, 128, 192, 160, 192, \"avg\", 128, '4d')\n",
    "    in4e = InceptionFactoryB(in4d, 128, 192, 192, 256, '4e')\n",
    "    # stage 4\n",
    "    in5a = InceptionFactoryA(in4e, 352, 192, 320, 160, 224, \"avg\", 128, '5a')\n",
    "    in5b = InceptionFactoryA(in5a, 352, 192, 320, 192, 224, \"max\", 128, '5b')\n",
    "    # global avg pooling\n",
    "    avg = mx.symbol.Pooling(data=in5b, kernel=(7, 7), stride=(1, 1), name=\"global_pool\", pool_type='avg')\n",
    "    # linear classifier\n",
    "    flatten = mx.symbol.Flatten(data=avg, name='flatten')\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=nhidden, name='fc')\n",
    "    softmax = mx.symbol.SoftmaxOutput(data=fc1, name='softmax')\n",
    "    return softmax\n",
    "\n",
    "softmax = inception(100, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data iterator. Note we convert original CIFAR-100 dataset into image format then pack into RecordIO in purpose of using our build-in image augmentation. For details about RecordIO, please refer ()[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[00:07:03] D:\\Program Files (x86)\\Jenkins\\workspace\\mxnet\\mxnet\\dmlc-core\\src\\io\\local_filesys.cc:109: LocalFileSystem.ListDirectory ./data error: No such process",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4ce8c6149900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprefetch_buffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     preprocess_threads=2)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m test_dataiter = mx.io.ImageRecordIter(\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\mxnet-0.9.4-py2.7.egg\\mxnet\\io.pyc\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mmx_uint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mparam_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             ctypes.byref(iter_handle)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\mxnet-0.9.4-py2.7.egg\\mxnet\\base.pyc\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \"\"\"\n\u001b[1;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [00:07:03] D:\\Program Files (x86)\\Jenkins\\workspace\\mxnet\\mxnet\\dmlc-core\\src\\io\\local_filesys.cc:109: LocalFileSystem.ListDirectory ./data error: No such process"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataiter = mx.io.ImageRecordIter(\n",
    "    shuffle=True,\n",
    "    path_imgrec=\"./data/train.rec\",\n",
    "    mean_img=\"./data/mean.bin\",\n",
    "    rand_crop=True,\n",
    "    rand_mirror=True,\n",
    "    data_shape=(3, 28, 28),\n",
    "    batch_size=batch_size,\n",
    "    prefetch_buffer=4,\n",
    "    preprocess_threads=2)\n",
    "\n",
    "test_dataiter = mx.io.ImageRecordIter(\n",
    "    path_imgrec=\"./data/test.rec\",\n",
    "    mean_img=\"./data/mean.bin\",\n",
    "    rand_crop=False,\n",
    "    rand_mirror=False,\n",
    "    data_shape=(3, 28, 28),\n",
    "    batch_size=batch_size,\n",
    "    prefetch_buffer=4,\n",
    "    preprocess_threads=2,\n",
    "    round_batch=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 38\n",
    "model_prefix = \"model/cifar_100\"\n",
    "\n",
    "softmax = inception(100, 1.0)\n",
    "\n",
    "model = mx.model.FeedForward(ctx=mx.gpu(), symbol=softmax, num_epoch=num_epoch,\n",
    "                             learning_rate=0.05, momentum=0.9, wd=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit first stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataiter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-80656f7a97d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(X=train_dataiter,\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0meval_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dataiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_end_callback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpeedometer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           epoch_end_callback=mx.callback.do_checkpoint(model_prefix))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataiter' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X=train_dataiter,\n",
    "          eval_data=test_dataiter,\n",
    "          eval_metric=\"accuracy\",\n",
    "          batch_end_callback=mx.callback.Speedometer(batch_size, 200),\n",
    "          epoch_end_callback=mx.callback.do_checkpoint(model_prefix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without reducing learning rate, this model is able to achieve state-of-art result.\n",
    "\n",
    "Let's reduce learning rate to train a few more rounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start training with [gpu(0)]\n",
      "INFO:root:Batch [200]\tSpeed: 147.84 samples/sec\n",
      "INFO:root:Batch [400]\tSpeed: 139.77 samples/sec\n",
      "INFO:root:Batch [600]\tSpeed: 140.17 samples/sec\n",
      "INFO:root:Iteration[0] Train-accuracy=0.951866\n",
      "INFO:root:Iteration[0] Time cost=353.261\n",
      "INFO:root:Iteration[0] Validation-accuracy=0.744924\n",
      "INFO:root:Saved checkpoint to \"model/cifar_100_stage2-0001.params\"\n",
      "INFO:root:Batch [200]\tSpeed: 141.02 samples/sec\n",
      "INFO:root:Batch [400]\tSpeed: 140.35 samples/sec\n",
      "INFO:root:Batch [600]\tSpeed: 140.39 samples/sec\n",
      "INFO:root:Iteration[1] Train-accuracy=0.976012\n",
      "INFO:root:Iteration[1] Time cost=356.142\n",
      "INFO:root:Iteration[1] Validation-accuracy=0.747213\n",
      "INFO:root:Saved checkpoint to \"model/cifar_100_stage2-0002.params\"\n",
      "INFO:root:Batch [200]\tSpeed: 140.77 samples/sec\n",
      "INFO:root:Batch [400]\tSpeed: 140.49 samples/sec\n",
      "INFO:root:Batch [600]\tSpeed: 139.74 samples/sec\n",
      "INFO:root:Iteration[2] Train-accuracy=0.983335\n",
      "INFO:root:Iteration[2] Time cost=356.680\n",
      "INFO:root:Iteration[2] Validation-accuracy=0.746716\n",
      "INFO:root:Saved checkpoint to \"model/cifar_100_stage2-0003.params\"\n",
      "INFO:root:Batch [200]\tSpeed: 140.64 samples/sec\n",
      "INFO:root:Batch [400]\tSpeed: 140.16 samples/sec\n",
      "INFO:root:Batch [600]\tSpeed: 140.17 samples/sec\n",
      "INFO:root:Iteration[3] Train-accuracy=0.987076\n",
      "INFO:root:Iteration[3] Time cost=356.758\n",
      "INFO:root:Iteration[3] Validation-accuracy=0.755971\n",
      "INFO:root:Saved checkpoint to \"model/cifar_100_stage2-0004.params\"\n",
      "INFO:root:Batch [200]\tSpeed: 140.58 samples/sec\n",
      "INFO:root:Batch [400]\tSpeed: 139.97 samples/sec\n",
      "INFO:root:Batch [600]\tSpeed: 139.89 samples/sec\n",
      "INFO:root:Iteration[4] Train-accuracy=0.989850\n",
      "INFO:root:Iteration[4] Time cost=358.025\n",
      "INFO:root:Iteration[4] Validation-accuracy=0.752090\n",
      "INFO:root:Saved checkpoint to \"model/cifar_100_stage2-0005.params\"\n",
      "INFO:root:Batch [200]\tSpeed: 140.18 samples/sec\n",
      "INFO:root:Batch [400]\tSpeed: 139.61 samples/sec\n",
      "INFO:root:Batch [600]\tSpeed: 139.32 samples/sec\n",
      "INFO:root:Iteration[5] Train-accuracy=0.991037\n",
      "INFO:root:Iteration[5] Time cost=358.366\n",
      "INFO:root:Iteration[5] Validation-accuracy=0.752886\n",
      "INFO:root:Saved checkpoint to \"model/cifar_100_stage2-0006.params\"\n",
      "INFO:root:Batch [200]\tSpeed: 140.42 samples/sec\n",
      "INFO:root:Batch [400]\tSpeed: 139.11 samples/sec\n",
      "INFO:root:Batch [600]\tSpeed: 139.29 samples/sec\n",
      "INFO:root:Iteration[6] Train-accuracy=0.992858\n",
      "INFO:root:Iteration[6] Time cost=358.961\n",
      "INFO:root:Iteration[6] Validation-accuracy=0.756867\n",
      "INFO:root:Saved checkpoint to \"model/cifar_100_stage2-0007.params\"\n"
     ]
    }
   ],
   "source": [
    "# load params from saved model\n",
    "num_epoch = 38\n",
    "model_prefix = \"model/cifar_100\"\n",
    "tmp_model = mx.model.FeedForward.load(model_prefix, epoch)\n",
    "\n",
    "# create new model with params\n",
    "num_epoch = 6\n",
    "model_prefix = \"model/cifar_100_stage2\"\n",
    "model = mx.model.FeedForward(ctx=mx.gpu(), symbol=softmax, num_epoch=num_epoch,\n",
    "                             learning_rate=0.01, momentum=0.9, wd=0.0001,\n",
    "                             arg_params=tmp_model.arg_params, aux_params=tmp_model.aux_params,)\n",
    "\n",
    "\n",
    "model.fit(X=train_dataiter,\n",
    "          eval_data=test_dataiter,\n",
    "          eval_metric=\"accuracy\",\n",
    "          batch_end_callback=mx.callback.Speedometer(batch_size, 200),\n",
    "          epoch_end_callback=mx.callback.do_checkpoint(model_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**\n",
    "\n",
    "[1] Ioffe, Sergey, and Christian Szegedy. \"Batch normalization: Accelerating deep network training by reducing internal covariate shift.\" arXiv preprint arXiv:1502.03167 (2015).\n",
    "\n",
    "[2] Xu, Bing, et al. \"Empirical Evaluation of Rectified Activations in Convolutional Network.\" arXiv preprint arXiv:1505.00853 (2015).\n",
    "\n",
    "[3] Srivastava, Rupesh Kumar, Klaus Greff, and JÃ¼rgen Schmidhuber. \"Highway Networks.\" arXiv preprint arXiv:1505.00387 (2015).\n",
    "\n",
    "[4] Lee, Chen-Yu, et al. \"Deeply-supervised nets.\" arXiv preprint arXiv:1409.5185 (2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
